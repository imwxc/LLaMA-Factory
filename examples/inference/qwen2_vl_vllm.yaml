model_name_or_path: Qwen/Qwen2-VL-7B-Instruct
template: qwen2_vl
infer_backend: vllm  # choices: [huggingface, vllm]
trust_remote_code: true
vllm_enforce_eager: true
vllm_gpu_util: 0.95
vllm_maxlen: 16384